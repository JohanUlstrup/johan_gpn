---
title: Notes to paperes
subtitle: Some subtitle for my thesis
authors:
  - name: Johan Ulstrup
    affiliation: Aarhus University
    roles: writing
    corresponding: true
keywords:
  - Vestibulum
  - Nunc ac dignissim 
  - Proin feugiat 
plain-language-summary: |
  In plain language, the thesis describes an analysis of something. Somethings was not previously know. I found something and was able to conclude something. The perspectives of this result is something.
key-points:
  - Proin tempor lorem arcu, at condimentum purus volutpat eu. 
  - Mauris cursus laoreet ex, ignissim bibendum est posuere iaculis.
  - Nam vel neque eu arcu blandit fringilla et in quam.
date: last-modified
date-format: long
degree: Master of Science in Bioinformatics
bibliography: references.bib
---

# DNA language models are powerful predictors of genome-wide variant effects

The idea for this project was to evaluate the Genome-Pretrained Network (GPN) introduced in (Kantorovitz2024) and determine whether it could achieve greater accuracy than traditional methods in predicting genome-wide variant effects.

The model is designed as a convolutional neural network (CNN) and takes input sequences with a window size of 512. During training, 15% of the positions within each window are masked to enable the model to learn meaningful representations.

The architecture consists of 25 layers, each structured as follows: a dilated convolution layer, followed by an add-and-norm layer with a skip connection from before the dilated convolution. This is followed by a feedforward layer, another add-and-norm layer, and additional skip connections.

A feedforward layer is a fundamental component of neural networks, where inputs pass through one or more fully connected layers with activation functions, transforming data without looping back. This structure helps the model learn complex representations by applying weighted transformations and non-linearities.

A dilated convolution expands the receptive field of a convolutional layer without increasing the number of parameters or reducing resolution. By spacing kernel elements apart, it captures long-range dependencies in sequences, making it particularly useful in genomic data analysis. When combined, dilated convolutions and feedforward layers enhance a modelâ€™s ability to recognize patterns across different scales efficiently.

After passing through the 25 layers, the model produces a contextual embedding with a dimension of 512 (D=512), followed by classification layers. The final layer outputs the probabilities of the four nucleotides at each masked position.

The GPN variant effect prediction score is calculated as the log-likelihood ratio between the alternate (ALT) and reference (REF) alleles. Here, L represents the window length in base pairs, and D denotes the embedding dimension.


::: {#fig-fig_1_kantorovitz}
![](illustrations/fig_1_kantorovitz.png){width="50%"}
:::
 



# Genome-wide coancestry reveals details of ancient and recent male-driven reticulation in baboons





# Bon mot

> Nothing in Biology Makes Sense except in the Light of Evolution
>
> \- Theodosius Dobzhansky






[@knuth84]dommi


# References

::: {#refs}
...
:::

