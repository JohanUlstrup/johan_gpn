{
  "hash": "d15d5f0ee87b0099388a77acd128defa",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Making a dataset for GPN \nexecute:\n  eval: false\n---\n\n\n\n\n## Imports and utility functions\n\n::: {#82d0818d .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nfrom pathlib import Path\nfrom gwf import Workflow, AnonymousTarget\nfrom gwf.workflow import collect\nimport glob\nimport yaml\nimport pandas as pd\nimport re\nimport time\n```\n:::\n\n\nInstantiate the workflow with the name of the project folder:\n\n::: {#839a2ca6 .cell execution_count=2}\n``` {.python .cell-code}\n# instantiate the workflow\n#gwf = Workflow(defaults={'account': 'baboons'})\ngwf = Workflow(defaults={'account': 'TopicsInBioinformatics'})\n\n\nconfig = yaml.safe_load(open(\"scripts/generate_dataset/workflow.yaml\"))\n\n# Define the base directory\nbase_dir = \"/home/johanulstrup/johan_gpn/people/johanulsrup/johan_gpn\"\n<<<<<<< HEAD\n\n=======\n#base_dir = \"/faststorage/project/johan_gpn/people/johanulsrup/johan_gpn\"\n>>>>>>> 4d3645e (WIP: save local changes)\n\n\n## loading data and preparatoin (pandas)\nassemblies = pd.read_csv(config['assemblies_path'], sep='\\t')\nassemblies[\"Assembly Name\"] = assemblies[\"Assembly Name\"].str.replace(\" \", \"_\")\nassemblies.set_index(\"Assembly Accession\", inplace=True)\nassemblies[\"genome_path\"] = [f\"{base_dir}/steps/tmp/{i}/ncbi_dataset/data/{i}/{i}_{n}_genomic.fna\" for i, n in zip(assemblies.index, assemblies[\"Assembly Name\"])]\nassemblies[\"annotation_path\"] = [f\"{base_dir}/steps/tmp/{i}/ncbi_dataset/data/{i}/genomic.gff\" for i in assemblies.index]\n```\n:::\n\n\nUtility functions:\n\n::: {#79106eb5 .cell execution_count=3}\n``` {.python .cell-code}\n# utility function\ndef modify_path(path, **kwargs):\n    \"\"\"\n    Utility function for modifying file paths substituting\n    the directory (dir), base name (base), or file suffix (suffix).\n    \"\"\"\n\n    for key in ['dir', 'base', 'suffix']:\n        kwargs.setdefault(key, None)\n    assert len(kwargs) == 3\n\n    par, name = os.path.split(path)\n    name_no_suffix, suf = os.path.splitext(name)\n    if type(kwargs['suffix']) is str:\n        suf = kwargs['suffix']\n    if kwargs['dir'] is not None:\n        par = kwargs['dir']\n    if kwargs['base'] is not None:\n        name_no_suffix = kwargs['base']\n\n    new_path = os.path.join(par, name_no_suffix + suf)\n    if type(kwargs['suffix']) is tuple:\n        assert len(kwargs['suffix']) == 2\n        new_path, nsubs = re.subn(r'{}$'.format(kwargs['suffix'][0]), kwargs['suffix'][1], new_path)\n        assert nsubs == 1, nsubs\n    \n\n    return new_path\n```\n:::\n\n\n## Template functions:\n\n::: {#ff6478ca .cell execution_count=4}\n``` {.python .cell-code}\n# task template function\ndef download_genome(assembly):\n    #print(f\"Downloading genome for assembly: {assembly}\")\n\n    tmp_dir = f\"{base_dir}/steps/tmp/{assembly}\"\n    genome_path = assemblies.loc[assembly, \"genome_path\"]\n    annotation_path = assemblies.loc[assembly, \"annotation_path\"]\n\n    inputs = [config['assemblies_path']]\n    genome_file = f\"{base_dir}/steps/genome/{assembly}.fa.gz\"\n    annotation_file = f\"{base_dir}/steps/annotation/{assembly}.gff.gz\"\n    outputs = [genome_file, annotation_file]\n    options = {'memory': '8g', 'walltime': '02:00:00'}\n\n    spec = f\"\"\"\n        orig=$(pwd)\n        mkdir -p {base_dir}/steps/genome && \n        mkdir -p {base_dir}/steps/annotation && \n        mkdir -p {tmp_dir} && \n        cd {tmp_dir} && \n        datasets download genome accession {assembly} --include genome,gff3 &&\n        unzip -o ncbi_dataset.zip && \n        cd $orig && \n        gzip -c {genome_path} > {genome_file} && \n        gzip -c {annotation_path} > {annotation_file} && rm -r {tmp_dir}\n    \"\"\"\n\n    #print(f\"Spec for {assembly}: {spec}\")\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n\ndef convert_fna_and_gff(assembly):\n    \"\"\"\n    Converts pre-downloaded .fna and .gff files to .fa.gz and .gff.gz\n    so they match the expected workflow input format.\n    \"\"\"\n    # Paths to pre-downloaded genome & annotation files\n    pre_downloaded_genome_path = \"/home/johanulstrup/johan_gpn/people/johanulsrup/johan_gpn/data/ncbi_dataset/data/GCF_000264685.3/GCF_000264685.3_Panu_3.0_genomic.fna\"\n    pre_downloaded_annotation_path = \"/home/johanulstrup/johan_gpn/people/johanulsrup/johan_gpn/data/ncbi_dataset/data/GCF_000264685.3/genomic.gff\"\n\n    # Destination paths\n    genome_file = f\"{base_dir}/steps/genome/{assembly}.fa.gz\"\n    annotation_file = f\"{base_dir}/steps/annotation/{assembly}.gff.gz\"\n\n    # Workflow settings\n    inputs = [pre_downloaded_genome_path, pre_downloaded_annotation_path]\n    outputs = [genome_file, annotation_file]\n    options = {'memory': '8g', 'walltime': '00:30:00'}\n\n    # Command to compress both files\n    spec = f\"\"\"\n        mkdir -p {base_dir}/steps/genome &&\n        mkdir -p {base_dir}/steps/annotation &&\n        gzip -c {pre_downloaded_genome_path} > {genome_file} &&\n        gzip -c {pre_downloaded_annotation_path} > {annotation_file}\n    \"\"\"\n\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n\n\ndef make_all_intervals(assembly):\n    inputs = [f\"{base_dir}/steps/genome/{assembly}.fa.gz\"]\n    outputs = [f\"{base_dir}/steps/intervals/{assembly}/all.parquet\"]\n    options = {'memory': '8g', 'walltime': '02:00:00'} \n    spec = f\"\"\"\n    mkdir -p {base_dir}/steps/intervals/{assembly} &&\n    python scripts/generate_dataset/make_all_intervals.py {inputs[0]} {outputs[0]} {config['window_size']}\n    \"\"\"\n    #print(f\"Spec for make_all_intervals {assembly}: {spec}\")\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\ndef make_defined_intervals(assembly): ## does not show up in gwf\n    inputs = [f\"{base_dir}/steps/genome/{assembly}.fa.gz\"]\n    outputs = [f\"{base_dir}/steps/intervals/{assembly}/defined.parquet\"]\n    options = {'memory': '8g', 'walltime': '02:00:00'} \n    spec = f\"\"\"\n    mkdir -p steps/intervals/{assembly} &&\n    python scripts/generate_dataset/make_defined_intervals.py {inputs[0]} {outputs[0]} {config['window_size']}\n    \"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\ndef make_annotation_intervals(assembly, feature):\n    inputs = [f\"{base_dir}/steps/intervals/{assembly}/defined.parquet\",\n              f\"{base_dir}/steps/genome/{assembly}.fa.gz\"]\n    outputs = [f\"{base_dir}/steps/intervals/{assembly}/annotation_{feature}.parquet\"]\n    options = {'memory': '8g', 'walltime': '02:00:00'} \n    include_flank = config.get(\"annotation_features_include_flank\", config['window_size'] // 2)\n    add_jiter = config.get(\"annotation_features_add_jitter\", 100)\n    spec = f\"\"\"\n    mkdir -p steps/intervals/{assembly} &&\n    python scripts/generate_dataset/make_annotation_intervals.py {inputs[0]} {inputs[1]} {outputs[0]} \\\n        {config['window_size']} {feature} {include_flank} {add_jiter}\n    \"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\ndef make_balanced_v1_intervals(assembly):  ### maybe not that inmpotent becuase it was the date created for the paper \n    inputs = [f\"{base_dir}/steps/intervals/{assembly}/defined.parquet\",\n              f\"{base_dir}/steps/annotation/{assembly}.gff.gz\"]\n    outputs = [f\"{base_dir}/steps/intervals/{assembly}/balanced_v1.parquet\"]\n    options = {'memory': '8g', 'walltime': '02:00:00'} \n    promoter_upstream = config.get(\"promoter_upstream\", 1000)\n    spec = f\"\"\"\n    mkdir -p steps/intervals/{assembly} &&\n    python scripts/generate_dataset/make_defined_intervals.py {inputs[0]} {outputs[0]} \\\n        {config['window_size']} {promoter_upstream}\n    \"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\ndef make_dataset_assembly(assembly):\n    splits = [\"train\", \"validation\", \"test\"]\n    inputs = [f\"{base_dir}/steps/intervals/{assembly}/{config['target_intervals']}.parquet\",      ### it ask for data in a folder that does not exist\n              f\"{base_dir}/steps/genome/{assembly}.fa.gz\"]                                        ### it ask for data in a folder that does not exist\n    outputs = [f\"{base_dir}/steps/dataset_assembly/{assembly}/{split}.parquet\" for split in splits]\n    options = {'memory': '32g', 'walltime': '02:00:00'} \n    spec = f\"\"\"\n    mkdir -p steps/intervals/{assembly} &&    \n<<<<<<< HEAD\n    python scripts/generategenerate_dataset_data_set/make_dataset_assembly.py {' '.join(inputs)} {' '.join(outputs)} \\\n=======\n    python scripts/generate_dataset/make_dataset_assembly.py {' '.join(inputs)} {' '.join(outputs)} \\\n>>>>>>> 4d3645e (WIP: save local changes)\n        {config['split_proportion']} {config['window_size']} {config['step_size']} {config['add_rc']} \\\n        {config['whitelist_validation_chroms']} {config['whitelist_test_chroms']}\n    \"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n## download_targets = gwf.map(download_genome, assemblies.index)\ndownload_targets = gwf.map(convert_fna_and_gff, assemblies.index)\n\n\nfrom gpn.data import (\n    Genome, load_table, get_balanced_intervals, filter_length,\n    filter_annotation_features,\n)\n\n<<<<<<< HEAD\ndef merge_datasets(assembly):\n    splits = [\"train\", \"validation\", \"test\"]\n    inputs = [f\"{base_dir}/steps/dataset_assembly/{assembly}/{split}.parquet\" for split in splits]\n    output_dir = f\"{base_dir}/steps/dataset/data/{assembly}\"\n    options = {'memory': '32g', 'walltime': '02:00:00'} \n    spec = f\"\"\"\n    mkdir -p {output_dir} &&    \n    python /faststorage/project/johan_gpn/people/johanulsrup/johan_gpn/scripts/generate_dataset/make_merge_datasets.py {' '.join(inputs)} {output_dir}\n    \"\"\"\n    return AnonymousTarget(inputs=inputs, outputs=[output_dir], options=options, spec=spec)\n=======\n# def merge_datasets(assembly):\n#     splits = [\"train\", \"validation\", \"test\"]\n#     inputs = [f\"{base_dir}/steps/dataset_assembly/{assembly}/{split}.parquet\" for split in splits]\n#     output_dir = f\"{base_dir}/steps/dataset/data/{assembly}\"\n#     options = {'memory': '32g', 'walltime': '02:00:00'} \n#     spec = f\"\"\"\n#     #python /faststorage/project/johan_gpn/people/johanulsrup/johan_gpn/scripts/generate_dataset/make_merge_datasets.py {' '.join(inputs)} {output_dir}\n#     python /home/johanulstrup/johan_gpn/people/johanulsrup/johan_gpn/scripts/generate_dataset/make_merge_datasets.py {' '.join(inputs)} {output_dir}\n#     \"\"\"\n#     return AnonymousTarget(inputs=inputs, outputs=[output_dir], options=options, spec=spec)\n>>>>>>> 4d3645e (WIP: save local changes)\n```\n:::\n\n\n## Logic for target intervals defind in the yaml file:\n# Intervals from fasta file used for training:\n# - \"all\": all positions\n# - \"defined\": positions with defined nucleotides (not N)\n# - \"annotation_{feature}\": only <feature> positions from annotation, e.g. CDS, exon\n# - \"balanced_v1\": recipe used in original paper\n\n::: {#e6d6e6bc .cell execution_count=5}\n``` {.python .cell-code}\nif config['target_intervals'] == 'all':\n    interval_targets = gwf.map(make_all_intervals, assemblies.index)\nelif config['target_intervals'] == 'defined':\n    print(\"Calling make_defined_intervals\")\n    interval_targets = gwf.map(make_defined_intervals, assemblies.index)  \nelif config['target_intervals'].startswith('annotation'):\n    feature = config['target_intervals'].replace('annotation_', '')\n    interval_targets = gwf.map(make_annotation_intervals, assemblies.index, feature)\nelif config['target_intervals'] == 'balanced_v1':\n    interval_targets = gwf.map(make_balanced_v1_intervals, assemblies.index)\nelse:\n    assert 0\n\ndatasets = gwf.map(make_dataset_assembly, assemblies.index)\n#merge_datasets_targets = gwf.map(merge_datasets, assemblies.index)\n\n# # %%\n```\n:::\n\n\n",
    "supporting": [
      "workflow_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}