{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af081148-1f5e-4af4-b562-845365785a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from genominterv.remapping import remap\n",
    "from genominterv.remapping import interval_distance, genomic\n",
    "from genominterv.remapping import remap_interval_data\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4aa162-5930-4f00-8c18-9d96586e56cb",
   "metadata": {},
   "source": [
    "Load file fasta fiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7395cf37-356d-4871-9834-53213b3c5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chrom  start  end  value\n",
      "0  chrX      1    5   80.0\n",
      "1  chrX      6   10   40.0\n",
      "2  chrX     11   15   80.0\n",
      "3  chrX     16   20   40.0\n",
      "4  chrX     21   25  100.0\n",
      "['chrX']\n",
      "(100000, 4)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/johanulstrup/johan_gpn/people/johanulsrup/johan_gpn/data/macaca/macaca_GC_percent_chrx\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_variable_step_wig(file_path):\n",
    "    data = []\n",
    "    chrom = None\n",
    "    span = 1\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"track\") or line.startswith(\"browser\"):\n",
    "                continue\n",
    "            elif line.startswith(\"variableStep\"):\n",
    "                tokens = line.split()\n",
    "                for token in tokens:\n",
    "                    if token.startswith(\"chrom=\"):\n",
    "                        chrom = token.split(\"=\")[1]\n",
    "                    elif token.startswith(\"span=\"):\n",
    "                        span = int(token.split(\"=\")[1])\n",
    "            else:\n",
    "                tokens = line.split()\n",
    "                if len(tokens) != 2:\n",
    "                    continue  # Skip malformed lines\n",
    "                start, value = int(tokens[0]), float(tokens[1])\n",
    "                end = start + span - 1\n",
    "                data.append({\n",
    "                    \"chrom\": chrom,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"value\": value\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_gc = load_variable_step_wig(file_path)  # or whatever the file is called\n",
    "\n",
    "print(df_gc.head())\n",
    "print(df_gc[\"chrom\"].unique())\n",
    "print(df_gc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f776661",
   "metadata": {},
   "source": [
    "## loading eigenvectors using kasper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a00008-d367-419b-a85a-b79326dc4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_compartment_data(file_name):\n",
    "    e1_100kb = pd.read_csv(file_name)\n",
    "    e1_100kb['start'] = [i*100_000 for i in range(e1_100kb.index.size)]\n",
    "    e1_100kb['end'] = e1_100kb.start + 100_000\n",
    "    e1_100kb['sign'] = np.sign(e1_100kb.e1)\n",
    "    e1_100kb['segment_id'] = ((e1_100kb.sign.shift() != e1_100kb.sign)).cumsum()\n",
    "    \n",
    "    comp = e1_100kb.groupby('segment_id', as_index=False).agg(dict(\n",
    "         e1=['mean', 'sum'], \n",
    "         start='min', \n",
    "         end='max', \n",
    "         segment_id='mean', \n",
    "         sign='mean'\n",
    "    ))\n",
    "    comp.columns = ['_'.join(col).strip() for col in comp.columns.values]\n",
    "    comp = comp.rename(\n",
    "        columns={'start_min':'start',\n",
    "                 'end_max':'end', \n",
    "                 'segment_id_mean':'segment_id', \n",
    "                 'sign_mean':'sign'}\n",
    "    )\n",
    "    comp['comp'] = ['A' if x > 0 else 'B' for x in comp.sign]\n",
    "    comp = comp.reset_index()\n",
    "    comp['chrom'] = 'chrX'\n",
    "    \n",
    "    _comp = comp.copy()\n",
    "    for i in range(1, _comp.index.size-1):\n",
    "        if np.isnan(_comp.loc[i-1, 'e1_mean']):\n",
    "            _comp.loc[i, 'start'] = np.nan\n",
    "        if np.isnan(_comp.loc[i+1, 'e1_mean']):\n",
    "            _comp.loc[i, 'end'] = np.nan\n",
    "    _comp = _comp.loc[~_comp.e1_mean.isnull(), :]\n",
    "    _comp = _comp.reset_index()\n",
    "    compartment_edges = pd.concat([_comp.start, _comp.end]).sort_values().unique()\n",
    "    \n",
    "    compartments = comp.loc[~comp.e1_mean.isnull()].copy()\n",
    "    compartments['start'] = compartments.start.astype(int)\n",
    "    compartments['end'] = compartments.end.astype(int)\n",
    "\n",
    "    return compartments, compartment_edges\n",
    "\n",
    "def edge_segments(compartment_edges, flank):\n",
    "    compartment_edge_segm = pd.DataFrame(np.column_stack((compartment_edges, compartment_edges+flank)), columns=['start', 'end'])\n",
    "    compartment_edge_segm['chrom'] = 'chrX'\n",
    "    return compartment_edge_segm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795aa135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated variable names: ['sperm_e1_100kb_10Mb_comps', 'round_spermatid_e1_100kb_10Mb_comps', 'pachytene_spermatocyte_e1_100kb_10Mb_comps', 'spermatogonia_e1_100kb_10Mb_comps', 'fibroblast_e1_100kb_10Mb_comps']\n",
      "Generated variable names: ['sperm_e1_100kb_10Mb_edges', 'round_spermatid_e1_100kb_10Mb_edges', 'pachytene_spermatocyte_e1_100kb_10Mb_edges', 'spermatogonia_e1_100kb_10Mb_edges', 'fibroblast_e1_100kb_10Mb_edges']\n",
      "Generated compartment A and B variables: ['sperm_e1_100kb_10Mb_edges_AB', 'sperm_e1_100kb_10Mb_edges_A', 'sperm_e1_100kb_10Mb_edges_B', 'round_spermatid_e1_100kb_10Mb_edges_AB', 'round_spermatid_e1_100kb_10Mb_edges_A', 'round_spermatid_e1_100kb_10Mb_edges_B', 'pachytene_spermatocyte_e1_100kb_10Mb_edges_AB', 'pachytene_spermatocyte_e1_100kb_10Mb_edges_A', 'pachytene_spermatocyte_e1_100kb_10Mb_edges_B', 'spermatogonia_e1_100kb_10Mb_edges_AB', 'spermatogonia_e1_100kb_10Mb_edges_A', 'spermatogonia_e1_100kb_10Mb_edges_B', 'fibroblast_e1_100kb_10Mb_edges_AB', 'fibroblast_e1_100kb_10Mb_edges_A', 'fibroblast_e1_100kb_10Mb_edges_B']\n",
      "  comp       start         end chrom\n",
      "0    B    800000.0    800001.0  chrX\n",
      "1    B   3400000.0   3400001.0  chrX\n",
      "2    A   8300000.0   8300001.0  chrX\n",
      "3    A  13400000.0  13400001.0  chrX\n",
      "4    A  15000000.0  15000001.0  chrX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load data\n",
    "eigentrack_dir = \"/home/johanulstrup/johan_gpn/people/johanulsrup/johan_gpn/data/eigentracks\"\n",
    "eigentrack_files = [\n",
    "    f for f in os.listdir(eigentrack_dir) if f.endswith(\"_10Mb.csv\")\n",
    "]\n",
    "\n",
    "comps_dict = {}\n",
    "edges_dict = {}\n",
    "generated_comps=[]\n",
    "generated_edges=[]\n",
    "a_and_b_comps = []\n",
    "\n",
    "for filename in eigentrack_files:\n",
    "    filepath = os.path.join(eigentrack_dir, filename)\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    comps_var = f\"{base}_comps\"\n",
    "    edges_var = f\"{base}_edges\"\n",
    "    comps, edges = parse_compartment_data(filepath)\n",
    "    comps_dict[comps_var] = comps\n",
    "    edges_dict[edges_var] = edges\n",
    "    generated_comps.append(comps_var)\n",
    "    generated_edges.append(edges_var)\n",
    "\n",
    "print(\"Generated variable names:\", generated_comps)\n",
    "print(\"Generated variable names:\", generated_edges)\n",
    "\n",
    "for edge_var in generated_edges:\n",
    "    # Get the numpy array of edges from the dictionary\n",
    "    edges = edges_dict[edge_var]\n",
    "    \n",
    "    # Create the DataFrame using edge_segments with flank=1\n",
    "    seg_name = f\"{edge_var}_interval\"\n",
    "    seg_df = edge_segments(edges, 1)\n",
    "    #print(f\"Created: {seg_name}\")\n",
    "\n",
    "    # Merge compartment assignment\n",
    "    comps_var = edge_var.replace(\"_edges\", \"_comps\")\n",
    "    if comps_var in comps_dict:\n",
    "        comps_df = comps_dict[comps_var]\n",
    "        \n",
    "        comp_df = pd.DataFrame({\n",
    "            'comp': comps_df['comp'].reset_index(drop=True),\n",
    "            'start': seg_df['start'].reset_index(drop=True),\n",
    "            'end': seg_df['end'].reset_index(drop=True),\n",
    "            'chrom': seg_df['chrom'].reset_index(drop=True)\n",
    "        })\n",
    "\n",
    "        # Save full merged comp_df\n",
    "        comp_full_name = f\"{edge_var}_interval_comp\"\n",
    "            # Save combined A and B compartments\n",
    "        comp_AB_name = f\"{edge_var}_AB\"\n",
    "        globals()[comp_AB_name] = comp_df\n",
    "        a_and_b_comps.append(comp_AB_name)\n",
    "\n",
    "        #print(f\"Created: {comp_full_name}\")\n",
    "\n",
    "        # Split into compartments A and B\n",
    "        comp_A = comp_df[comp_df['comp'] == 'A'].reset_index(drop=True)\n",
    "        comp_B = comp_df[comp_df['comp'] == 'B'].reset_index(drop=True)\n",
    "\n",
    "        # Save A and B splits as new variables\n",
    "        comp_A_name = f\"{edge_var}_A\"\n",
    "        comp_B_name = f\"{edge_var}_B\"\n",
    "        globals()[comp_A_name] = comp_A\n",
    "        globals()[comp_B_name] = comp_B\n",
    "        a_and_b_comps.append(comp_A_name)\n",
    "        a_and_b_comps.append(comp_B_name)\n",
    "        \n",
    "        #print(f\"Created: {edge_var}_A and {edge_var}_B\")\n",
    "\n",
    "print(\"Generated compartment A and B variables:\", a_and_b_comps)\n",
    "\n",
    "#print(sperm_e1_100kb_10Mb_edges_A.head())\n",
    "\n",
    "print(globals()[comp_AB_name].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbe16f",
   "metadata": {},
   "source": [
    "## not nesesary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a67f6197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of sperm_e1_100kb_10Mb_edges_AB:\n",
      "  comp       start         end chrom\n",
      "0    A   2500000.0   2500001.0  chrX\n",
      "1    A   8300000.0   8300001.0  chrX\n",
      "2    A   9800000.0   9800001.0  chrX\n",
      "3    A  10000000.0  10000001.0  chrX\n",
      "4    B  10400000.0  10400001.0  chrX\n",
      "\n",
      "Head of round_spermatid_e1_100kb_10Mb_edges_AB:\n",
      "  comp      start        end chrom\n",
      "0    A  7900000.0  7900001.0  chrX\n",
      "1    A  8000000.0  8000001.0  chrX\n",
      "2    A  8400000.0  8400001.0  chrX\n",
      "3    B  8500000.0  8500001.0  chrX\n",
      "4    A  8900000.0  8900001.0  chrX\n",
      "\n",
      "Head of pachytene_spermatocyte_e1_100kb_10Mb_edges_AB:\n",
      "  comp       start         end chrom\n",
      "0    A   9000000.0   9000001.0  chrX\n",
      "1    A   9100000.0   9100001.0  chrX\n",
      "2    B   9800000.0   9800001.0  chrX\n",
      "3    A  10000000.0  10000001.0  chrX\n",
      "4    B  10500000.0  10500001.0  chrX\n",
      "\n",
      "Head of spermatogonia_e1_100kb_10Mb_edges_AB:\n",
      "  comp       start         end chrom\n",
      "0    A   9700000.0   9700001.0  chrX\n",
      "1    A  10000000.0  10000001.0  chrX\n",
      "2    B  10100000.0  10100001.0  chrX\n",
      "3    A  10200000.0  10200001.0  chrX\n",
      "4    B  10400000.0  10400001.0  chrX\n",
      "\n",
      "Head of fibroblast_e1_100kb_10Mb_edges_AB:\n",
      "  comp       start         end chrom\n",
      "0    B    800000.0    800001.0  chrX\n",
      "1    B   3400000.0   3400001.0  chrX\n",
      "2    A   8300000.0   8300001.0  chrX\n",
      "3    A  13400000.0  13400001.0  chrX\n",
      "4    A  15000000.0  15000001.0  chrX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for edge_var in generated_edges:\n",
    "    comp_AB_name = f\"{edge_var}_AB\"\n",
    "    if comp_AB_name in globals():\n",
    "        print(f\"Head of {comp_AB_name}:\")\n",
    "        print(globals()[comp_AB_name].head())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffa1ff",
   "metadata": {},
   "source": [
    "## remapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78bb82fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     start      end  start_prox  end_prox chrom  start_orig  end_orig  value  \\\n",
      "0 -2499995 -2499999         NaN       NaN  chrX           1         5   80.0   \n",
      "1 -2499990 -2499994         NaN       NaN  chrX           6        10   40.0   \n",
      "2 -2499985 -2499989         NaN       NaN  chrX          11        15   80.0   \n",
      "3 -2499980 -2499984         NaN       NaN  chrX          16        20   40.0   \n",
      "4 -2499975 -2499979         NaN       NaN  chrX          21        25  100.0   \n",
      "\n",
      "         mid     absmid  \n",
      "0 -2499997.0  2499997.0  \n",
      "1 -2499992.0  2499992.0  \n",
      "2 -2499987.0  2499987.0  \n",
      "3 -2499982.0  2499982.0  \n",
      "4 -2499977.0  2499977.0  \n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "    # Clean and sort\n",
    "sperm_clean = sperm_e1_100kb_10Mb_edges_AB.dropna(subset=[\"start\", \"end\"]).copy()\n",
    "sperm_clean[\"start\"] = sperm_clean[\"start\"].astype(int)\n",
    "sperm_clean[\"end\"] = sperm_clean[\"end\"].astype(int)\n",
    "df_gc = df_gc.dropna(subset=[\"start\", \"end\"]).copy()\n",
    "df_gc[\"start\"] = df_gc[\"start\"].astype(int)\n",
    "df_gc[\"end\"] = df_gc[\"end\"].astype(int)\n",
    "\n",
    "sperm_clean = sperm_clean.sort_values(by=['chrom', 'start', 'end'])\n",
    "df_gc = df_gc.sort_values(by=['chrom', 'start', 'end'])\n",
    "\n",
    "result = remap_interval_data(df_gc, sperm_clean, include_prox_coord=True)\n",
    "# Post-process\n",
    "result[\"mid\"] = (result[\"start\"] + result[\"end\"]) / 2\n",
    "result[\"absmid\"] = result[\"mid\"].abs()\n",
    "#result = result.dropna(subset=[\"start\", \"end\", \"mid\", \"absmid\", \"start_prox\", \"end_prox\"], how=\"any\")\n",
    "\n",
    "print(result.head())\n",
    "\n",
    "print(result[\"start_prox\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
